{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-m8DNLYBjsX",
        "outputId": "eb95ea41-dd5b-4f25-98ec-28d4e58ec2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_malloc_managed.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cuda_malloc_managed.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 1000000  // Array size\n",
        "\n",
        "__global__ void squareKernel(int *arr, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        arr[idx] *= arr[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "void usingUnifiedMemory() {\n",
        "    int *d_arr;\n",
        "    cudaMallocManaged(&d_arr, N * sizeof(int));\n",
        "    for (int i = 0; i < N; i++) d_arr[i] = i + 1;\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    squareKernel<<<(N + 255) / 256, 256>>>(d_arr, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    double duration = std::chrono::duration<double, std::milli>(end - start).count();\n",
        "    printf(\"Unified Memory Time: %.3f ms\\n\", duration);\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "}\n",
        "\n",
        "void usingGlobalMemory() {\n",
        "    int *h_arr, *d_arr;\n",
        "    h_arr = (int*)malloc(N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_arr, N * sizeof(int));\n",
        "\n",
        "    for (int i = 0; i < N; i++) h_arr[i] = i + 1;\n",
        "    cudaMemcpy(d_arr, h_arr, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    squareKernel<<<(N + 255) / 256, 256>>>(d_arr, N);\n",
        "    cudaMemcpy(h_arr, d_arr, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    double duration = std::chrono::duration<double, std::milli>(end - start).count();\n",
        "    printf(\"Global Memory Time: %.3f ms\\n\", duration);\n",
        "\n",
        "    free(h_arr);\n",
        "    cudaFree(d_arr);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    usingUnifiedMemory();\n",
        "    usingGlobalMemory();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cuda_malloc_managed.cu -o cuda_malloc_managed\n",
        "!./cuda_malloc_managed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOjFu3lOB_H6",
        "outputId": "8dc00df4-242c-4697-a1a9-62b27697127e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unified Memory Time: 1.600 ms\n",
            "Global Memory Time: 0.857 ms\n"
          ]
        }
      ]
    }
  ]
}